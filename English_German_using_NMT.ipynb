{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHECRIFh8ZRO"
      },
      "source": [
        "In this lab, we will try to use the OpenNMT library to train an NMT model using the toy English-German dataset.\n",
        "\n",
        "This notebook was found originally at:\n",
        "https://github.com/OpenNMT/OpenNMT-py#quickstart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CClOS9iT1Fsp",
        "outputId": "0ea278d1-3add-46b5-8648-7b206b59dcb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/OpenNMT/OpenNMT-py.git"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/OpenNMT/OpenNMT-py.git 'C:\\Users\\vsvik\\AppData\\Local\\Temp\\pip-req-build-11uqk6l8'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "  Cloning https://github.com/OpenNMT/OpenNMT-py.git to c:\\users\\vsvik\\appdata\\local\\temp\\pip-req-build-11uqk6l8\n",
            "  Resolved https://github.com/OpenNMT/OpenNMT-py.git to commit fc3409ce08785915728dac9e9c9fb49f73027917\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from OpenNMT-py==2.2.0) (1.9.0)\n",
            "Collecting torchtext==0.5.0\n",
            "  Downloading torchtext-0.5.0-py3-none-any.whl (73 kB)\n",
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Collecting tensorboard>=2.3\n",
            "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
            "Collecting flask\n",
            "  Downloading Flask-2.1.2-py3-none-any.whl (95 kB)\n",
            "Collecting waitress\n",
            "  Downloading waitress-2.1.1-py3-none-any.whl (57 kB)\n",
            "Collecting pyonmttok<2,>=1.23\n",
            "  Downloading pyonmttok-1.31.0-cp39-cp39-win_amd64.whl (13.9 MB)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from OpenNMT-py==2.2.0) (6.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp39-cp39-win_amd64.whl (1.1 MB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (4.62.1)\n",
            "Requirement already satisfied: requests in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (2.27.1)\n",
            "Requirement already satisfied: six in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (1.16.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from torchtext==0.5.0->OpenNMT-py==2.2.0) (1.22.1)\n",
            "Collecting absl-py>=0.4\n",
            "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (0.37.1)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.20.1-cp39-cp39-win_amd64.whl (904 kB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from tensorboard>=2.3->OpenNMT-py==2.2.0) (58.0.4)\n",
            "Collecting grpcio>=1.24.3\n",
            "  Downloading grpcio-1.46.1-cp39-cp39-win_amd64.whl (3.5 MB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py==2.2.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.3->OpenNMT-py==2.2.0) (3.7.0)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (1.26.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from requests->torchtext==0.5.0->OpenNMT-py==2.2.0) (2.0.10)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from torch>=1.6.0->OpenNMT-py==2.2.0) (4.0.1)\n",
            "Requirement already satisfied: click>=8.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from flask->OpenNMT-py==2.2.0) (8.0.3)\n",
            "Collecting itsdangerous>=2.0\n",
            "  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from flask->OpenNMT-py==2.2.0) (3.0.3)\n",
            "Requirement already satisfied: colorama in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from click>=8.0->flask->OpenNMT-py==2.2.0) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vsvik\\anaconda3\\envs\\nlplab\\lib\\site-packages (from Jinja2>=3.0->flask->OpenNMT-py==2.2.0) (2.0.1)\n",
            "Building wheels for collected packages: OpenNMT-py\n",
            "  Building wheel for OpenNMT-py (setup.py): started\n",
            "  Building wheel for OpenNMT-py (setup.py): finished with status 'done'\n",
            "  Created wheel for OpenNMT-py: filename=OpenNMT_py-2.2.0-py3-none-any.whl size=222756 sha256=4eb5e93f4e18e3ee1c5abcf754c0e7ffd296cfd586a4ec54e16188c629846ce7\n",
            "  Stored in directory: C:\\Users\\vsvik\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-otd1pts_\\wheels\\ca\\98\\c3\\5b4cbbdb1d595b4bf163488914782db68c3a7fac8e98857d3c\n",
            "Successfully built OpenNMT-py\n",
            "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, sentencepiece, protobuf, markdown, itsdangerous, grpcio, google-auth-oauthlib, absl-py, waitress, torchtext, tensorboard, pyonmttok, flask, configargparse, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-2.2.0 absl-py-1.0.0 cachetools-5.0.0 configargparse-1.5.3 flask-2.1.2 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.46.1 itsdangerous-2.1.2 markdown-3.3.7 oauthlib-3.2.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyonmttok-1.31.0 requests-oauthlib-1.3.1 rsa-4.8 sentencepiece-0.1.96 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 torchtext-0.5.0 waitress-2.1.1 werkzeug-2.1.2\n"
          ]
        }
      ],
      "source": [
        "# Install OpenNMT-py 2.x\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\n",
        "\n",
        "!pip3 install git+https://github.com/OpenNMT/OpenNMT-py.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        },
        "id": "Esz4fKZRGVvx",
        "outputId": "43f05b93-f958-4a38-805e-03fa83d7ada6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0\n",
            "  Downloading https://download.pytorch.org/whl/cu92/torch-1.6.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (552.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 552.8 MB 4.5 kB/s \n",
            "\u001b[?25hCollecting future\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting numpy\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 37.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=edcdc2b6a6522061e82850c57cdb27004c29c129963d1c5f7505f1954b911de8\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "Successfully built future\n",
            "Installing collected packages: numpy, future, torch\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0+cu92 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.6.0+cu92 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0+cu92 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed future-0.18.2 numpy-1.21.6 torch-1.11.0+cu113\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# On Google Colab ONLY\n",
        "# Reinstall Torch to avoid incompatibility with Cuda 10.1\n",
        "\n",
        "# NOTE: By the end of the insatallation, it might ask for restarting the runtime...\n",
        "# In this case, just click the \"RESTART RUNTIME\" button.\n",
        "\n",
        "!pip3 install --ignore-installed torch==1.6.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj-PhnzqzMBQ",
        "outputId": "f477c759-170b-4ce8-f5d7-62673cd908ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-13 08:17:46--  https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.84.222\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.84.222|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1662081 (1.6M) [application/x-gzip]\n",
            "Saving to: ‘toy-ende.tar.gz’\n",
            "\n",
            "toy-ende.tar.gz     100%[===================>]   1.58M  8.37MB/s    in 0.2s    \n",
            "\n",
            "2022-05-13 08:17:46 (8.37 MB/s) - ‘toy-ende.tar.gz’ saved [1662081/1662081]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the files of the QuickStart\n",
        "\n",
        "!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
        "!tar xf toy-ende.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7oLWNaPZ_3m",
        "outputId": "1785a0af-9bf4-4e1f-b8a3-f1e27f174438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src-test.txt   src-val.txt   tgt-train.txt\n",
            "src-train.txt  tgt-test.txt  tgt-val.txt\n"
          ]
        }
      ],
      "source": [
        "# Optional: List the extracted files\n",
        "\n",
        "!cd toy-ende/ && ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUxHPm8izhzJ",
        "outputId": "cf22c9a0-a74d-46a0-f8b8-05b0bc6c0643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It is not acceptable that , with the help of the national bureaucracies , Parliament &apos;s legislative prerogative should be made null and void by means of implementing provisions whose content , purpose and extent are not laid down in advance .\n",
            "Federal Master Trainer and Senior Instructor of the Italian Federation of Aerobic Fitness , Group Fitness , Postural Gym , Stretching and Pilates; from 2004 , he has been collaborating with Antiche Terme as personal Trainer and Instructor of Stretching , Pilates and Postural Gym .\n",
            "&quot; Two soldiers came up to me and told me that if I refuse to sleep with them , they will kill me . They beat me and ripped my clothes .\n"
          ]
        }
      ],
      "source": [
        "# Optional: Print the first 3 lines of the source file\n",
        "\n",
        "!head -n 3 toy-ende/src-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOXCYqXOM9un",
        "outputId": "14d0c820-1135-415c-f55d-3b7d6f5f565e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of lines:\n",
            "10000 toy-ende/src-train.txt\n"
          ]
        }
      ],
      "source": [
        "# Optional: Check the number of lines in the source file\n",
        "\n",
        "!echo \"Number of lines:\" && wc -l toy-ende/src-train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jgYJhuzzh96",
        "outputId": "d7968248-88f6-49cf-da8d-df14a9eb47b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# toy_en_de.yaml\n",
            "\n",
            "## Where the samples will be written\n",
            "save_data: toy-ende/run/example\n",
            "\n",
            "## Where the vocab(s) will be written\n",
            "src_vocab: toy-ende/run/example.vocab.src\n",
            "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
            "\n",
            "## Where the model will be saved\n",
            "save_model: model/model\n",
            "\n",
            "# Prevent overwriting existing files in the folder\n",
            "overwrite: False\n",
            "\n",
            "# Corpus opts:\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: toy-ende/src-train.txt\n",
            "        path_tgt: toy-ende/tgt-train.txt\n",
            "    valid:\n",
            "        path_src: toy-ende/src-val.txt\n",
            "        path_tgt: toy-ende/tgt-val.txt\n",
            "\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Remove or modify these lines for bigger files\n",
            "train_steps: 1000\n",
            "valid_steps: 200\n"
          ]
        }
      ],
      "source": [
        "# Create the YAML configuration file\n",
        "# On a regular machine, you can create it manually or with nano\n",
        "\n",
        "config = '''# toy_en_de.yaml\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: toy-ende/run/example\n",
        "\n",
        "## Where the vocab(s) will be written\n",
        "src_vocab: toy-ende/run/example.vocab.src\n",
        "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
        "\n",
        "## Where the model will be saved\n",
        "save_model: model/model\n",
        "\n",
        "# Prevent overwriting existing files in the folder\n",
        "overwrite: False\n",
        "\n",
        "# Corpus opts:\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: toy-ende/src-train.txt\n",
        "        path_tgt: toy-ende/tgt-train.txt\n",
        "    valid:\n",
        "        path_src: toy-ende/src-val.txt\n",
        "        path_tgt: toy-ende/tgt-val.txt\n",
        "\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Remove or modify these lines for bigger files\n",
        "train_steps: 1000\n",
        "valid_steps: 200\n",
        "'''\n",
        "\n",
        "with open(\"toy_en_de.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)\n",
        "\n",
        "!cat toy_en_de.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade OpenNMT-py==2.0.0rc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDJWwjS0g9BX",
        "outputId": "b65c55df-19bb-4e94-e468-1d43cf24f152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py==2.0.0rc1\n",
            "  Downloading OpenNMT_py-2.0.0rc1-py3-none-any.whl (219 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 40 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 219 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (1.11.0+cu113)\n",
            "Collecting torchtext==0.4.0\n",
            "  Downloading torchtext-0.4.0-py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting pyonmttok>=1.19.*\n",
            "  Downloading pyonmttok-1.31.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (16.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 16.6 MB 28.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (4.64.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (2.8.0)\n",
            "Collecting configargparse\n",
            "  Downloading ConfigArgParse-1.5.3-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (0.18.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (1.15.0)\n",
            "Collecting waitress\n",
            "  Downloading waitress-2.1.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py==2.0.0rc1) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (1.21.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.0.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.4.0->OpenNMT-py==2.0.0rc1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py==2.0.0rc1) (3.2.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.0.0rc1) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.0.0rc1) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask->OpenNMT-py==2.0.0rc1) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->OpenNMT-py==2.0.0rc1) (2.0.1)\n",
            "Installing collected packages: waitress, torchtext, pyonmttok, configargparse, OpenNMT-py\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.12.0\n",
            "    Uninstalling torchtext-0.12.0:\n",
            "      Successfully uninstalled torchtext-0.12.0\n",
            "Successfully installed OpenNMT-py-2.0.0rc1 configargparse-1.5.3 pyonmttok-1.31.0 torchtext-0.4.0 waitress-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRMJGSan8FoF",
        "outputId": "54c18820-ffdc-455b-81af-617114561a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_build_vocab\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/build_vocab.py\", line 63, in main\n",
            "    build_vocab_main(opts)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/bin/build_vocab.py\", line 23, in build_vocab_main\n",
            "    ArgumentParser.validate_prepare_opts(opts, build_vocab_only=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/utils/parse.py\", line 130, in validate_prepare_opts\n",
            "    cls._validate_vocab_opts(opt, build_vocab_only=build_vocab_only)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/utils/parse.py\", line 98, in _validate_vocab_opts\n",
            "    cls._validate_file(opt.src_vocab, info='src vocab')\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/onmt/utils/parse.py\", line 18, in _validate_file\n",
            "    raise IOError(f\"Please check path of your {info} file!\")\n",
            "OSError: Please check path of your src vocab file!\n"
          ]
        }
      ],
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "!onmt_build_vocab -config toy_en_de.yaml -n_sample -1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxPUCzdPgCTr",
        "outputId": "41e0e66a-70c9-4c45-e7f4-dde2fc12b2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRMNMIBzziDs"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is active\n",
        "# If not, go to \"Runtime\" menu > \"Change runtime type\" > \"GPU\"\n",
        "\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhpACn0WFQgG"
      },
      "outputs": [],
      "source": [
        "# Make sure the GPU is visable to PyTorch\n",
        "\n",
        "import torch\n",
        "\n",
        "gpu_id = torch.cuda.current_device()\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(gpu_id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6mgFwEX90UP"
      },
      "outputs": [],
      "source": [
        "# Train the NMT model\n",
        "\n",
        "!onmt_train -config toy_en_de.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQtKJduoXCz7"
      },
      "outputs": [],
      "source": [
        "# Translate\n",
        "\n",
        "!onmt_translate -model model/model_step_1000.pt -src toy-ende/src-test.txt -output toy-ende/pred_1000.txt -gpu 0 -verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uWerf-6pqsm"
      },
      "source": [
        "Install Sacrebleu to evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLET3PKMpvdD"
      },
      "outputs": [],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mX6CfM3WVVz7"
      },
      "outputs": [],
      "source": [
        "!sacrebleu toy-ende/tgt-test.txt < toy-ende/pred_1000.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlvtrX0fE2b"
      },
      "source": [
        "## Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-abxzBjpfE2b"
      },
      "source": [
        " #### A1 \n",
        "  - Please note down the BLEU scores obtained above in the cell below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywqwFsNHfE2c"
      },
      "source": [
        "* (note down results here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCmsDKx1fE2c"
      },
      "source": [
        "#### A2 \n",
        "\n",
        " - Your assginment is to train a model using the OpenNMT library as shown above but with larger dataset.\n",
        "\n",
        " - You can use any parallel corpus available from [Samanantar](https://indicnlp.ai4bharat.org/samanantar/)\n",
        "\n",
        " - Train a model on a single language pair and evaluate it using BLEU score as a metric as shown above.\n",
        "\n",
        " - Also note down the hyperparameters used for training the model. \n",
        "\n",
        " - As a class you can discuss amongst yourselves and can collectively try different hyperparameters. \n",
        "\n",
        " - If the parallel corpus is hard to fit in the GPU memory then you can use a smaller dataset, but if you are collectively trying different hyperparameters then all of you should experiment with the same dataset.\n",
        "\n",
        " - (Optional) You can further try to byte-pair encode the corpus and re-train the model. [The byte-pair encoding code is available in this notebook.](https://github.com/cfiltnlp/IITB-English-Hindi-PC/blob/main/IITB_En_Hi_Get_Data.ipynb) This notebook contains the code for byte-pair encoding the [IITB-English Hindi Parallel Corpus](https://huggingface.co/datasets/cfilt/iitb-english-hindi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEvvI1yafE2c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}